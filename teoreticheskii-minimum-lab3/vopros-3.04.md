# Вопрос №3.04

> Модель `agglomerative clustering`

Агломеративная иерархическая кластеризация — это метод «снизу вверх», который начинается с каждого объекта в отдельном кластере и последовательно объединяет ближайшие кластеры, пока не останется один кластер или пока не будет достигнуто требуемое число кластеров.

## Краткое описание алгоритма

1. Начало: каждый объект — отдельный кластер.
2. Вычислить матрицу попарных расстояний между кластерами.
3. Найти пару кластеров с минимальным расстоянием по выбранному правилу связи (linkage).
4. Объединить эту пару в новый кластер.
5. Обновить матрицу расстояний (пересчитать расстояния от нового кластера до остальных).
6. Повторять шаги 3–5 до остановки (число кластеров, порог расстояния, или полная агрегация).

## Правила связи (основные)

*   Single linkage (минимальное расстояние):

    $$
    d(A,B)=\min_{x\in A,y\in B}|x-y|.
    $$
*   Complete linkage (максимальное расстояние):

    $$
    d(A,B)=\max_{x\in A,y\in B}|x-y|.
    $$
*   Average linkage (среднее попарное):

    $$
    d(A,B)=\frac{1}{|A||B|}\sum_{x\in A}\sum_{y\in B}|x-y|.
    $$
*   Centroid linkage (расстояние между центроидами):

    $$
    d(A,B)=|\mu_A-\mu_B|,\quad \mu_A=\frac{1}{|A|}\sum_{x\in A}x.
    $$
*   Ward linkage (минимизация прироста суммы квадратов отклонений):

    $$
    \Delta SSE = \text{SSE}(A\cup B)-\text{SSE}(A)-\text{SSE}(B),
    $$

    выбирают объединение с наименьшим $$\Delta SSE$$. Требует евклидовой метрики.

Обновление расстояний может быть выражено через обобщённую формулу Лэнса–Уильямса:

$$
d(C_{ij},k)=\alpha_i d(i,k)+\alpha_j d(j,k)+\beta d(i,j)+\gamma |d(i,k)-d(j,k)|.
$$

Параметры $$\alpha_i,\alpha_j,\beta,\gamma$$ зависят от выбранной связи.

## Дендограмма

* Результат — дерево (дендограмма). Отрезки показывают уровни расстояний объединения.
* Чтобы получить разбиение на $$k$$ кластеров, «разрезают» дендограмму горизонтально на соответствующей высоте.

## Сложность и ресурсы

* Простая реализация: хранение матрицы расстояний $$O(n^2)$$ по памяти.
* Время: наивная реализация до $$O(n^3)$$, оптимизированные алгоритмы (например с обслуживанием ближайших соседей) — примерно $$O(n^2)$$.
* Практически подходит для $$n$$ до нескольких тысяч. Для десятков тысяч требуется специальные структуры или приближённые методы.

## Особенности и поведение

* Single linkage даёт «цепочки» (chaining). Хорош для вытянутых форм, чувствителен к шуму.
* Complete linkage даёт компактные, равномерные кластеры. Менее чувствителен к шуму, но может разрывать естественные вытянутые кластеры.
* Average linkage — компромисс, часто устойчивее.
* Ward — эффективен для поиска компактных сферических кластеров и часто даёт хорошие результаты при нормированных признаках. Требует евклидовой метрики.
* Centroid linkage может привести к «инверсиям» (нестандартная монотонность расстояний), что усложняет интерпретацию дендограммы.

## Практические рекомендации

* Масштабировать признаки (стандарт/мин-макс) перед применением.
* Выбирать метррику расстояния осознанно (евклид для Ward, можно использовать косинус/манхэттен для других связей).
* Для больших наборов данных рассмотреть сначала снижение размерности (PCA) или выборку.
* Визуализировать дендограмму и выбирать порог/$$k$$ по характерным «перепадам» высоты объединений.
* Если нужны кластеры произвольной формы и масштабируемость важна, рассмотреть DBSCAN/HDBSCAN вместо иерархии.

## Когда использовать

* Нужна иерархическая структура кластеров.
* Небольшие/средние наборы данных (до нескольких тысяч точек).
* Требуется визуальный анализ (дендограмма).
* Когда заранее неизвестно количество кластеров и хочется изучить разбиения на разных уровнях.

## Короткая шпаргалка для сдачи

* Алгоритм: начинаем с одиночных точек, итеративно объединяем ближайшие кластеры.
* Основные linkages: single, complete, average, centroid, Ward.
* Память: $$O(n^2)$$, время: оптимизированно $$O(n^2)$$.
* Ward = минимизировать прирост внутри-классовой суммы квадратов.
* Для получения $$k$$ кластеров «режем» дендрограмму на высоте, соответствующей нужному уровню объединений.
