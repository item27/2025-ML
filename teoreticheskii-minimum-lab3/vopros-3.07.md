# Вопрос №3.07

> Зачем нужны методы снижения размерности? На чем лучше обучать модели: на данных до снижения или после?

Коротко: методы снижения размерности нужны чтобы убрать шум и избыточность, ускорить обучение и визуализировать данные. Обучать лучше на тех данных, которые сохраняют предсказательную информацию — иногда это исходные признаки, иногда их низкоразмерная проекция. Решение принимают по валидации и здравому смыслу.

## Зачем нужны (кратко)

* Борьба с проклятием размерности.
* Уменьшение шума и коррелированности признаков.
* Снижение времени обучения и памяти.
* Предобработка для визуализации (2D/3D).
* Компрессия и уменьшение риска переобучения.

## Основные методы

*   PCA — линейная проекция на собственные векторы ковариации. Проекция:

    $$
    Z = XW,
    $$

    где $$W$$ — матрица из собственных векторов ковариации. Доля объяснённой дисперсии для компоненты $$i$$:

    $$
    \frac{\lambda_i}{\sum_j\lambda_j}.
    $$
* LDA — супервизированное снижение, максимизирует между- и минимизирует внутри-классовую дисперсию.
* Автоэнкодеры — нелинейная проекция через нейросеть.
* t-SNE / UMAP — для визуализации (не рекомендуется напрямую использовать как фичи для обучения без осторожности).
* Feature selection (L1, tree-importance) — не проекция, а выбор полезных признаков.

## На чём обучать — правила практики

1. Если цель — **визуализация** → снижать (t-SNE/UMAP/PCA).
2. Если данные имеют много шума/коллинеарности и мало наблюдений → чаще снижать (PCA/autoencoder/feature selection).
3. Если задача **супервизированная** и есть методы супервизированного DR (LDA, Supervised PCA) — предпочесть их.
4. Если модель нечувствительна к масштабу/корреляции (деревья, бустинг) — иногда оставлять исходные признаки; снижение может ухудшить интерпретируемость.
5. Для моделей, использующих евклидову метрику (k-means, KNN) — снижение часто полезно.
6. Всегда: **делать трансформацию только на тренировочной части** и применять к валидации/тесту (чтобы избежать утечки).

## Практический рабочий процесс

1. Оценить соотношение $$n$$ и $$d$$ (наблюдений и признаков).
2. Масштабировать/стандартизовать при необходимости.
3. Попробовать варианты: (a) исходные признаки, (b) PCA с порогом объяснённой дисперсии (например $$90%-95%$$), (c) супервизированный отбор.
4. Сравнить по кросс-валидации метрики качества модели.
5. Учесть интерпретируемость и требования к ресурсу.
6. Выбрать вариант, дающий лучшую валидационную производительность и приемлемую интерпретируемость.

## Короткие рекомендации для сдачи

* DR нужен для борьбы с шумом, скоростью и проклятием размерности.
* PCA хорош для линейной компрессии; t-SNE/UMAP — для визуализации.
* В супервизированных задачах предпочтительны супервизированные методы или отбор признаков.
* Всегда проверять на валидации и не допускать утечки (fit только на train).
