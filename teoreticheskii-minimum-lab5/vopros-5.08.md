# Вопрос №5.08

> Как CNN превращает картинку в эмбеддинг

Эмбеддинг изображения — это вектор $$z \in \mathbb{R}^d$$ (например, $$d=128, 512, 2048$$), который **компактно описывает** картинку так, чтобы “похожие” картинки имели близкие векторы.

#### 1) Вход как тензор

Картинка приводится к тензору $$x \in \mathbb{R}^{H \times W \times C}$$ (например, $$224 \times 224 \times 3$$), нормализуется.

#### 2) Свёрточные блоки делают карты признаков

После нескольких блоков Conv(+BN+ReLU)+Pooling/Stride получаем:

$$
F \in \mathbb{R}^{H' \times W' \times C'}
$$

* $$H', W'$$ обычно уменьшаются (downsampling),
* $$C'$$ обычно растёт (больше каналов = больше “типов” признаков).

Интуитивно: ранние слои — границы/текстуры, глубже — части объектов, ещё глубже — более “семантичные” признаки.

#### 3) Сведение по пространству (из карты в вектор)

Чтобы получить вектор, нужно убрать измерения $$H'$$ и $$W'$$. Делают обычно так:

**Global Average Pooling (GAP):** для каждого канала берём среднее по $$H' \times W'$$:

$$
v_c = \frac{1}{H'W'}\sum_{h,w} F(h,w,c)
$$

получаем $$v \in \mathbb{R}^{C'}$$.

Иногда вместо GAP используют:

* Global Max Pooling,
* Flatten + полносвязный слой (дороже и чаще хуже обобщает).

#### 4) Проекция в нужную размерность (собственно эмбеддинг)

Дальше часто стоит линейный слой (или MLP), который превращает $$v$$ в эмбеддинг:

$$
z = Wv + b,\quad z \in \mathbb{R}^d
$$

Иногда делают нормализацию (для поиска по похожести):

$$
z \leftarrow \frac{z}{|z|}
$$

#### 5) Как это обучается

CNN учится так, чтобы эмбеддинги были полезны задаче. Типовые варианты:

* **Классификация:** добавляют “голову” (linear → softmax) и обучают по кросс-энтропии. Эмбеддинг берут **до** последнего классификатора.
* **Метрическое обучение:** Triplet loss / contrastive / ArcFace и т.п. Цель — чтобы похожие изображения были ближе в пространстве $$z$$, а разные — дальше.
* **Self-supervised:** SimCLR/MoCo и др. — эмбеддинг учится без явных меток через пары “аугментаций” одной картинки.

***

### Что делать с эмбеддингом

#### 1) Поиск похожих изображений (retrieval)

Считаем эмбеддинги всех картинок в базе и ищем ближайшие к запросу (по косинусной близости или L2):

$$
\text{sim}(z_1, z_2) = \frac{z_1 \cdot z_2}{|z_1||z_2|}
$$

Использование: “найди похожие товары”, “найди похожие лица”, “дубликаты”.

#### 2) Кластеризация

K-means/DBSCAN по эмбеддингам → группируем похожие картинки без разметки.

#### 3) Классификация “поверх эмбеддинга”

Можно обучить простой классификатор (логрег/линейный слой, SVM) на $$z$$. Это удобно для transfer learning: CNN как “экстрактор”, сверху лёгкая модель.

#### 4) Детекция аномалий

Если эмбеддинг сильно “далёк” от эмбеддингов нормальных примеров — это кандидат на аномалию (брак, странное фото).

#### 5) Визуализация

t-SNE/UMAP по $$z$$, чтобы посмотреть, как данные группируются.

