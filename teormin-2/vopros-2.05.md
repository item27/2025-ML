# Вопрос №1.05

> Что такое переобучение?

**Ответ:**

**Переобучение** - это ситуация, когда модель **слишком хорошо запоминает** обучающие данные, включая шум и случайные особенности, и **теряет способность обобщать** знания на новые данные.

То есть модель показывает **высокую точность на обучающей выборке**, но **плохие результаты на тестовой**.

**Пример:**

Студент заучил ответы на конкретные билеты, но не понял сам предмет.

На экзамене с другими вопросами он “проваливается” - это и есть переобучение.

**Признаки переобучения:**

* Ошибка (loss) на **train** сильно меньше, чем на **test**;
* Модель показывает отличные результаты на знакомых данных, но плохо работает на новых;
* Поведение модели нестабильно: небольшие изменения входных данных дают сильно разные результаты.

**Основные причины переобучения:**

1. **Слишком сложная модель** (много параметров, слоёв, глубины дерева);
2. **Мало данных** - модель «запоминает» шумы;
3. **Долгое обучение** - параметры подгоняются под случайные детали обучающего набора;
4. **Отсутствие регуляризации** - модель ничем не ограничивается;
5. **Неудачное разбиение данных** - тестовые данные похожи на обучающие.

**Как бороться с переобучением:**

* **Регуляризация** (L1, L2, Dropout) - добавляет штраф за слишком большие веса;
* **Упрощение модели** - уменьшение числа параметров или глубины дерева;
* **Больше данных** - особенно если есть шум или дисбаланс;
* **Кросс-валидация** - помогает оценить устойчивость модели;
* **Раннее прекращение обучения (Early stopping)** - остановка, когда ошибка на валидации начинает расти;
* **Аугментация данных** - создание новых примеров на основе существующих (в задачах CV, NLP и т.д.).
