# Вопрос №1.04

> Что такое мягкая классификация?

**Ответ:**

**Мягкая классификация** - это подход, при котором модель выдает **вероятность принадлежности объекта к каждому классу**, а не просто окончательное решение («0» или «1»).

То есть модель оценивает **уверенность** в каждом варианте и оставляет возможность неопределённости.

**Пример:**

Для задачи «кошки против собак» модель может выдать:

* Кошка - 0.85;
* Собака - 0.15.

На основе этого мы можем выбрать порог (например, 0.5) и сделать решение, но также знаем **насколько модель уверена** в своём ответе

**Отличие от жёсткой (hard) классификации:**

| Тип классификации  | Что выдаёт модель           | Пример результата             | Где полезно                                                               |
| ------------------ | --------------------------- | ----------------------------- | ------------------------------------------------------------------------- |
| **Жёсткая (Hard)** | Конкретный класс            | «Кошка»                       | Когда важно просто решение, без оценки уверенности                        |
| **Мягкая (Soft)**  | Вероятности по всем классам | «Кошка — 0.85, Собака — 0.15» | Когда важно понимать степень уверенности (медицина, финансы, риск-анализ) |

**Примеры мягких классификаторов:**

* **Логистическая регрессия** — выдаёт вероятность принадлежности к классу;
* **Naive Bayes**, **нейронные сети**, **градиентный бустинг** — часто возвращают вероятностные оценки;
* В `sklearn` такие модели имеют метод `.predict_proba()`.

**Когда это важно:**

* При **нечётких границах между классами** (например, "здоров / на грани болезни");
* При **асимметричных рисках ошибок** — когда ложноположительная и ложноотрицательная ошибки имеют разную цену;
* Для **калибровки модели** и **построения ROC / PR кривых**.
