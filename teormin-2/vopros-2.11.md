# Вопрос №1.11

> Что такое регуляризация? Как устроены L1 и L2 регуляризации

**Ответ:**

**Регуляризация** — это способ **борьбы с переобучением**, при котором к функции потерь добавляется **штраф за сложность модели** (обычно за большие веса).

**Идея:**

> Модель должна быть не только точной на обучении, но и достаточно “простой” (гладкой), чтобы не запоминать шум.

**Общая форма функции потерь с регуляризацией**

$$
\min_w \; L(X, y, w) = \min_w \left( |Xw - y|^2 + \lambda |w|_k \right)
$$

где

* $$|Xw - y|^2$$ — основная ошибка (например, MSE),
* $$\lambda$$ — коэффициент регуляризации (гиперпараметр),
* $$|w|_k$$ — штраф за сложность модели (в зависимости от типа регуляризации).

**L1-регуляризация (Lasso)**

$$
|w|_1 = |w_1| + |w_2| + ... + |w_D|
$$

Добавляется штраф пропорционально **абсолютным значениям весов**.

* Зануляет часть весов → делает модель **разреженной (sparse)**.
* Может использоваться для **отбора признаков**.
* Но менее устойчива при мультиколлинеарности (если признаки сильно коррелированы).

Пример:

$$
L = MSE + \lambda \sum |w_i|
$$

**L2-регуляризация (Ridge)**

$$
|w|_2^2 = w_1^2 + w_2^2 + ... + w_D^2
$$

Добавляется штраф пропорционально **квадратам весов**.

* “Сжимает” все веса, но **не зануляет** их.
* Делает модель **более стабильной** и устойчивой к шуму и мультиколлинеарности.
* Часто используется по умолчанию (например, в `LinearRegression` → `Ridge`).

$$
L = MSE + \lambda \sum w_i^2
$$

**Elastic Net (L1 + L2)**

**Комбинирует оба подхода:**

$$
L = MSE + \lambda_1 \sum |w_i| + \lambda_2 \sum w_i^2
$$

* Контролирует и разреженность, и стабильность;
* Применяется, когда много признаков, часть из которых коррелированы.

**Геометрическая интуиция**

* **L1** ограничивает веса “ромбом” → некоторые пересечения с осями → зануление весов.
* **L2** ограничивает веса “кругом” → веса уменьшаются плавно, но не становятся нулевыми.

**Сравнение L1 и L2**

| Характеристика                | **L1 (Lasso)**       | **L2 (Ridge)** |
| ----------------------------- | -------------------- | -------------- |
| Формула штрафа                | ∑                    | w\_i           |
| Эффект на веса                | Обнуляет часть весов | Уменьшает все  |
| Результат                     | Разреженная модель   | Гладкая модель |
| Отбор признаков               | Да                   | Нет            |
| Чувствительность к корреляции | Высокая              | Низкая         |
| Решение                       | Неаналитическое      | Аналитическое  |
