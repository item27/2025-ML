# Вопрос №1.10

> Зачем делить данные на train, test, val? Чем val отличается от test? Кросс-валидация, ее виды. Что такое data leak

**Ответ:**

**Train (обучающая выборка)**

Используется для **обучения модели** - подбора параметров (весов).

Модель “учится” находить закономерности именно на этих данных.

**Validation (валидационная выборка)**

Используется для **подбора гиперпараметров** и **оценки качества** во время обучения.

* помогает следить за переобучением (если на train всё лучше, а на val хуже - модель переобучается);
* используется при **early stopping**;
* _важно:_ модель “видит” эти данные косвенно, через оптимизацию гиперпараметров.

**Test (тестовая выборка)**

Используется **только один раз - для финальной оценки модели.**

Модель не должна “видеть” эти данные **ни напрямую, ни косвенно.**

→ Это имитация работы модели на реальных, ранее невиданных данных.

**Почему нужно делить данные:**

* чтобы корректно измерить способность модели _обобщать_, а не просто запоминать;
* чтобы избежать “подглядывания” в тест, которое приводит к ложному ощущению высокого качества (data leakage).

**Разница между Validation и Test**

| Параметр                       | Validation              | Test               |
| ------------------------------ | ----------------------- | ------------------ |
| Используется для               | Подбора гиперпараметров | Финальной оценки   |
| Влияет на обучение             | Да (через выбор модели) | Нет                |
| Видит ли модель данные         | Частично                | Никогда            |
| Можно использовать многократно | Да                      | Нет - только 1 раз |

**Кросс-валидация (Cross-validation)**

**Идея:**

Если данных немного, можно использовать их эффективнее, многократно чередуя обучение и проверку.

**K-Fold Cross-Validation**

1. Разделяем данные на _k_ частей (folds);
2. _k_ раз обучаем модель:

* на _k−1_ частях - train;
* на оставшейся - validation;

3. Итоговая метрика - среднее значение по всем итерациям.

Позволяет получить **устойчивую оценку качества**, не теряя данных на отдельную validation-выборку.

**Виды:**

* **K-Fold** - базовый вариант;
* **Stratified K-Fold** - сохраняет соотношение классов (важно при дисбалансе);
* **Leave-One-Out (LOO)** - особый случай, когда каждый пример по очереди становится тестом;
* **TimeSeries Split** - для временных рядов (учитывает порядок времени, не перемешивает данные).

**Data Leakage (утечка данных)**

**Data Leak** - это ситуация, когда информация из теста (или целевой переменной) **неявно попадает в процесс обучения**.

В результате модель “читает ответы” и показывает нереально высокие метрики, но **проваливается на реальных данных**.

**Примеры:**

* Вычисление статистик (mean, std) по всему датасету, включая test;
* Использование фич, напрямую зависящих от таргета (например, “revenue\_next\_month” при прогнозе текущего месяца);
* Подбор гиперпараметров по тестовой выборке.

**Правильный подход:**

Все трансформации (нормализация, масштабирование, кодирование) нужно **fit’ить только на train**, а затем **применять (transform)** к validation и test.
