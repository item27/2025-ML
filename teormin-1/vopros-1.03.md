# Вопрос №1.03

> Как и зачем перебирать гиперпараметры?

**Ответ:**

**Гиперпараметры** сильно влияют на качество модели.

Если задать их неправильно - модель может:

* **переобучиться** (слишком хорошо подстроиться под тренировочные данные и плохо работать на новых);
* **недообучиться** (не уловить закономерности);
* работать **слишком медленно** или **нестабильно**.

Поэтому гиперпараметры нужно **настраивать**, чтобы найти оптимальный баланс между точностью и обобщающей способностью модели.

Для корректной настройки гиперпараметров данные обычно делятся на три части:

* **Training set (тренировочная выборка)** - для обучения модели с заданными гиперпараметрами;
* **Validation set (валидационная выборка)** - для оценки разных вариантов гиперпараметров и выбора лучшего;
* **Test set (тестовая выборка)** - для финальной проверки модели, чтобы убедиться, что она не переобучилась под валидацию.

Иногда вместо отдельного validation set используют **кросс-валидацию (cross-validation)** - деление данных на несколько подвыборок, чтобы оценка модели была более надёжной.

**Основные методы подбора гиперпараметров:**

1. **Grid Search (полный перебор)**

* Перебираются **все возможные комбинации** гиперпараметров из заданных диапазонов;
* Гарантирует нахождение оптимума (если он есть в сетке), но **очень медленный**, особенно при большом количестве параметров.

2. **Random Search (случайный перебор)**

* Случайным образом выбираются комбинации гиперпараметров;
* **Быстрее**, чем Grid Search, и часто находит хорошие решения за меньшее число попыток.

3. **Байесовская оптимизация (Bayesian Optimization)**

* Строит **вероятностную модель целевой функции** (качества модели) и **выбирает следующие точки** для проверки так, чтобы максимально быстро найти хорошие параметры;
* Эффективна при дорогих вычислениях и большом числе гиперпараметров (Optuna).
