# Вопрос №1.15

> Дисбаланс классов: как влияет на метрики и модели, как с этим справиться

**Ответ:**

**Дисбаланс классов** — это ситуация, когда одни классы в данных встречаются **значительно чаще**, чем другие.

**Примеры:**

* 99% транзакций — нормальные, 1% — мошенничество.
* 95% пациентов здоровы, 5% больны.

**Почему это проблема:**

1. **Модель смещается** в сторону большинства (предсказывает его почти всегда).

→ Можно получить accuracy = 99%, просто говоря “все норм”.

2. **Обычные метрики вводят в заблуждение**:

* **Accuracy** будет высокой, даже если модель не видит редкий класс.
* **Precision / Recall / F1** — дают более честную оценку.

3. **Переобучение на частом классе** — модель “запоминает” паттерны только мажоритарного класса.

**Как влияет на метрики:**

| Метрика                           | Что происходит при дисбалансе                            |
| --------------------------------- | -------------------------------------------------------- |
| **Accuracy**                      | Становится бесполезной (высока даже при плохом качестве) |
| **Precision / Recall**            | Более информативны, но нужно смотреть оба                |
| **F1-score**                      | Балансирует precision и recall                           |
| **ROC-AUC**                       | Сохраняет устойчивость к дисбалансу                      |
| **PR-AUC (Precision-Recall AUC)** | Часто информативнее, чем ROC-AUC при сильном дисбалансе  |

**Как бороться с дисбалансом:**

**Корректировать данные**

* **Oversampling (пересэмплирование меньшинства)** — дублируем объекты редкого класса или создаём синтетические примеры

(например, метод **SMOTE** — Synthetic Minority Oversampling Technique).

* **Undersampling (удаление части большинства)** — уменьшаем количество примеров частого класса.

_Минус:_ теряем часть данных.

* **Аугментация данных** — создаём новые примеры с помощью шумов, преобразований, генераторов (в задачах CV, NLP и др.).

**Изменить обучение модели**

* **Взвешивание классов (class weights)** — штраф за ошибку в редком классе делаем выше.

Пример: `class_weight='balanced'` в sklearn.

* **Cost-sensitive learning** — явно задаём разные стоимости ошибок (FP/FN).
* **Использовать подходящие алгоритмы** — деревья, бустинги, ансамбли (Random Forest, XGBoost) могут устойчиво работать при дисбалансе.

**Менять постановку задачи**

* Рассматривать редкий класс как **аномалию (anomaly detection)**;
* Переформулировать задачу (например, бинаризация “редкий vs остальные”).

**Как оценивать модель при дисбалансе**

Использовать метрики, чувствительные к редкому классу:

* **Precision, Recall, F1-score (macro / weighted)**
* **ROC-AUC, PR-AUC**
* **Confusion Matrix** — чтобы видеть, где именно ошибки.

Пример

При 99% "0" и 1% "1":

модель, всегда предсказывающая “0”

→ Accuracy = 0.99

→ Recall для класса “1” = 0

→ F1 = 0
