# Вопрос №8.07

> Чем [Deep Convolutional GAN](https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/) отличается от простого GAN

### Чем DCGAN отличается от “простого” GAN

**GAN** — это идея (игра $$G$$ против $$D$$). **DCGAN** — это конкретный “правильный” выбор архитектуры для изображений: **глубокие свёрточные сети** вместо MLP, плюс набор правил, чтобы обучение было стабильнее и качество картинок выше.

#### Коротко в таблице

|                            | “Простой” GAN (часто vanilla)                     | DCGAN                                                                                                                              |
| -------------------------- | ------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- |
| Как подаём картинку        | обычно **flatten** $$28\times28 \rightarrow 784$$ | работаем как с изображением: **Conv2d**                                                                                            |
| Архитектура $$D$$          | MLP (fully connected)                             | strided **Conv2d** для downsample (без pooling)                                                                                    |
| Архитектура $$G$$          | MLP (fully connected)                             | **ConvTranspose2d** (“fractionally-strided”) для upsample                                                                          |
| Пространственная структура | часто теряется                                    | сохраняется, поэтому качество лучше ([learnopencv.com](https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/)) |
| Стабилизация обучения      | не обязательно                                    | BatchNorm в $$G$$ и $$D$$ (с оговорками)                                                                                           |
| Активации                  | любые                                             | $$G$$: ReLU, на выходе Tanh; $$D$$: LeakyReLU                                                                                      |
| Fully-connected слои       | часто много                                       | стараются **убрать скрытые FC** (кроме “проекции” шума в начало)                                                                   |

***

### Почему DCGAN обычно лучше для картинок

1. **Свёртки используют локальность**: модель учит края, штрихи, части цифры и т.д. MLP по “плоскому” вектору часто хуже сохраняет структуру изображения. ([learnopencv.com](https://learnopencv.com/deep-convolutional-gan-in-pytorch-and-tensorflow/))
2. **Strided conv вместо pooling**: downsample становится обучаемым (сеть сама учит, как сжимать).
3. **ConvTranspose в генераторе**: апсемплинг тоже обучаемый, можно аккуратно наращивать размер feature map до картинки.
4. **BatchNorm + правильные активации** заметно стабилизируют GAN-обучение и уменьшают шанс коллапса.

***

### “Правила DCGAN” (то, что обычно ожидают на защите)

Из оригинальной работы DCGAN:

* заменить pooling на **strided convolutions** в $$D$$ и **fractionally-strided/ConvTranspose** в $$G$$
* использовать **BatchNorm** в $$G$$ и $$D$$ (обычно не ставят BN на вход $$D$$ и на выход $$G$$)
* убрать “лишние” fully-connected скрытые слои
* $$G$$: ReLU везде, на выходе Tanh
* $$D$$: LeakyReLU

Часто вместе с этим берут и типовые настройки из статьи: нормализация входных изображений в $$[-1,1]$$ (под Tanh), инициализация весов $$\mathcal{N}(0, 0.02)$$, Adam с $$lr=0.0002$$ и $$\beta_1=0.5$$.

***

### Что НЕ меняется относительно простого GAN

* сама игра $$G$$ vs $$D$$ и adversarial loss по смыслу те же; DCGAN — это в первую очередь **архитектура и стабилизация** для изображений.
