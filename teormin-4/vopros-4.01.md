# Вопрос №4.01

> Что такое эмбеддинг? Является ли строка датасета эмбеддингом? является ли выход линейного слоя нейросети эмбеддингом? Что такое запутанное представление? [Объяснимость и интерпретируемость моделей](https://en.wikipedia.org/wiki/Explainable_artificial_intelligence) - в чем разница?

## Что такое эмбеддинг

Эмбеддинг — это плотный числовой вектор фиксированной длины, полученный обучением модели так, чтобы похожие объекты (слова, товары, пользователей) имели близкие координаты. Его можно рассматривать как «компактный паспорт» объекта: в нём уже закодированы семантические признаки, необходимые для последующей модели.

* Получается либо обучением специального слоя (embedding layer), либо как скрытое состояние нейросети.
* Почему работает: модель оптимизирует функцию потерь, заставляя векторные расстояния отражать смысловое сходство.

## Является ли строка датасета эмбеддингом

Нет. Строка датасета — это исходные данные (текст, набор признаков, метки). Пока они не преобразованы моделью, никакой структуры «сходства» в них не заложено. Даже если строка — это набор чисел, она описывает сырые признаки, а не обученное представление.

## Является ли выход линейного слоя эмбеддингом

Только в том случае, если этот слой специально обучен на задачу получения представлений. Линейный слой сам по себе просто применяет матрицу весов. Если он стоит, например, сразу перед softmax и оптимизируется «до конца» задачи классификации, то его выход — скрытое состояние. Оно может служить эмбеддингом (им часто пользуются как признаками), но термин «эмбеддинг» корректен, когда слой обучается на цель «представить объект», а не только «предсказать класс». Поэтому обычно так называют:

* Специальный embedding-слой, преобразующий ID токена в вектор.
* Последнюю скрытую репрезентацию encoder модели, если она используется повторно в других задачах.

## Запутанное (entangled) представление

Запутанное представление — это вектор, компоненты которого зависят сразу от многих скрытых факторов. Изменение одного измерения влияет одновременно на несколько смыслов, поэтому трудно сказать «эта координата = род деятельности, а эта = возраст». Disentangled (развязанные) представления устроены наоборот: каждый фактор (цвет, форма, время) соответствует отдельному измерению или их небольшой группе. В практике NLP и CV добиться полностью disentangled репрезентаций сложно; большинство эмбеддингов запутаны.

## Объяснимость vs интерпретируемость

| Термин | Что значит | Примеры |
| --- | --- | --- |
| **Интерпретируемость (interpretability)** | Степень, в которой устройство модели и её параметры прозрачны человеку. Саму модель можно «читать». | Линейная регрессия с несколькими признаками: коэффициенты напрямую говорят о влиянии признаков. |
| **Объяснимость (explainability)** | Методы и процедуры, которые помогают понять, почему модель (в том числе «чёрный ящик») выдала конкретный ответ. Может быть постфактум объяснение. | SHAP, LIME, attention визуализации: они не упрощают внутреннюю модель, но строят понятное объяснение. |

Коротко: интерпретируемая модель понятна изначально, объяснимая модель обзаводится дополнительным пояснением (post-hoc). Большие нейросети редко интерпретируемы, поэтому требуется explainability-инструменты.
