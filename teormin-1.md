## Вопрос №1

> Чем обучение с учителем отличается от обучения без учителя. Какое отношение оно имеет к кластеризации, классификации, регрессии, ранжирования, генерации

**Ответ:**

**Обучение с учителем (Supervised Learning)** - это подход, при котором у нас есть **размеченные данные**, то есть для каждого объекта известен правильный ответ (целевая переменная - _target_). Модель учится находить зависимость между входными признаками (_features_) и целевым значением (_target_), чтобы потом делать прогнозы на новых данных.

**Типы задач обучения с учителем:**

- **Классификация** - предсказание категории, к которой относится объект.

Пример: определить, спам ли письмо, к какому классу относится изображение.

- **Регрессия** - предсказание числового значения.

Пример: прогноз цены квартиры, спроса и т. д.

- **Ранжирование** - упорядочивание объектов по какому-то критерию.

Пример: упорядочить результаты поиска по степени релевантности.

- **Генерация** - создание новых объектов, похожих на обучающие данные.

Пример: генерация изображений, текста или музыки по примеру.

**Обучение без учителя (Unsupervised Learning)** - подход, когда данные **не размечены**, и правильных ответов нет. Модель сама ищет скрытые закономерности, группы или структуры в данных. Приходится вводить эвристики для оценки эффективности модели, но в целом поиск `верных` ответов не является самой целью.

**Типы задач обучения без учителя:**

- **Кластеризация** - объединение объектов в группы (кластеры) по схожим признакам.

Пример: сегментация клиентов по поведению.

- **Поиск ассоциативных правил** - выявление закономерностей и зависимостей между признаками.

Пример: правило «если покупают молоко, часто берут и хлеб».

- **Уменьшение размерности** - сокращение числа признаков при сохранении важной информации.

Пример: визуализация данных в 2D (PCA, t-SNE).

- **Рекомендательные системы** - подбор похожих объектов на основе схожести пользователей или товаров.

Пример: «покупатели, похожие на вас, выбрали…».

**Главные различия:**

- В _обучении с учителем_ есть “правильные ответы” и задача - **научиться их предсказывать**.

- В _обучении без учителя_ ответов нет - задача **найти структуру или закономерности** в данных.

## Вопрос №2

> Что такое параметры модели? Что такое гиперпараметры?

**Ответ:**

**Параметры модели** - это внутренние значения (веса, коэффициенты), которые модель **проставляет сама** во время тренировки, чтобы лучше предсказывать результат.

Они напрямую влияют на то, как модель делает прогнозы.

**Примеры параметров:**

- Коэффициенты и свободный член в **линейной регрессии**;

- Веса и смещения (**weights** и **biases**) в **нейронной сети**.

Параметры подбираются **автоматически** при обучении, чтобы минимизировать ошибку (функцию потерь).

**Гиперпараметры** - это **настройки самой модели или процесса обучения**, которые задаются **вручную до начала обучения**. Они определяют, _как_ будет проходить обучение и _какой вид_ примет модель.

**Примеры гиперпараметров:**

- Скорость обучения (**learning rate**) в градиентном спуске;

- Количество слоёв и нейронов в **нейронной сети**;

- Количество кластеров в **K-Means**;

- Глубина дерева в **Random Forest**;

- Коэффициенты регуляризации (**L1, L2**).

Гиперпараметры **не обучаются автоматически** - их подбирают с помощью перебора (Grid Search, Random Search, Optuna).

## Вопрос №3

> Как и зачем перебирать гиперпараметры?

**Ответ:**

**Гиперпараметры** сильно влияют на качество модели.

Если задать их неправильно - модель может:

- **переобучиться** (слишком хорошо подстроиться под тренировочные данные и плохо работать на новых);

- **недообучиться** (не уловить закономерности);

- работать **слишком медленно** или **нестабильно**.

Поэтому гиперпараметры нужно **настраивать**, чтобы найти оптимальный баланс между точностью и обобщающей способностью модели.

Для корректной настройки гиперпараметров данные обычно делятся на три части:

- **Training set (тренировочная выборка)** - для обучения модели с заданными гиперпараметрами;

- **Validation set (валидационная выборка)** - для оценки разных вариантов гиперпараметров и выбора лучшего;

- **Test set (тестовая выборка)** - для финальной проверки модели, чтобы убедиться, что она не переобучилась под валидацию.

Иногда вместо отдельного validation set используют **кросс-валидацию (cross-validation)** - деление данных на несколько подвыборок, чтобы оценка модели была более надёжной.

**Основные методы подбора гиперпараметров:**

1. **Grid Search (полный перебор)**

- Перебираются **все возможные комбинации** гиперпараметров из заданных диапазонов;

- Гарантирует нахождение оптимума (если он есть в сетке), но **очень медленный**, особенно при большом количестве параметров.

2. **Random Search (случайный перебор)**

- Случайным образом выбираются комбинации гиперпараметров;

- **Быстрее**, чем Grid Search, и часто находит хорошие решения за меньшее число попыток.

3. **Байесовская оптимизация (Bayesian Optimization)**

- Строит **вероятностную модель целевой функции** (качества модели) и **выбирает следующие точки** для проверки так, чтобы максимально быстро найти хорошие параметры;

- Эффективна при дорогих вычислениях и большом числе гиперпараметров (Optuna).

## Вопрос №4

> Что такое мягкая классификация?

**Ответ:**

**Мягкая классификация** - это подход, при котором модель выдает **вероятность принадлежности объекта к каждому классу**, а не просто окончательное решение («0» или «1»).

То есть модель оценивает **уверенность** в каждом варианте и оставляет возможность неопределённости.

**Пример:**

Для задачи «кошки против собак» модель может выдать:

- Кошка - 0.85;

- Собака - 0.15.

На основе этого мы можем выбрать порог (например, 0.5) и сделать решение, но также знаем **насколько модель уверена** в своём ответе

**Отличие от жёсткой (hard) классификации:**

| Тип классификации | Что выдаёт модель | Пример результата | Где полезно |
| ------------------ | --------------------------- | ----------------------------- | ------------------------------------------------------------------------- |
| **Жёсткая (Hard)** | Конкретный класс | «Кошка» | Когда важно просто решение, без оценки уверенности |
| **Мягкая (Soft)** | Вероятности по всем классам | «Кошка — 0.85, Собака — 0.15» | Когда важно понимать степень уверенности (медицина, финансы, риск-анализ) |

**Примеры мягких классификаторов:**

- **Логистическая регрессия** — выдаёт вероятность принадлежности к классу;

- **Naive Bayes**, **нейронные сети**, **градиентный бустинг** — часто возвращают вероятностные оценки;

- В `sklearn` такие модели имеют метод `.predict_proba()`.

**Когда это важно:**

- При **нечётких границах между классами** (например, "здоров / на грани болезни");

- При **асимметричных рисках ошибок** — когда ложноположительная и ложноотрицательная ошибки имеют разную цену;

- Для **калибровки модели** и **построения ROC / PR кривых**.

## Вопрос №5

> Что такое переобучение?

**Ответ:**

**Переобучение** - это ситуация, когда модель **слишком хорошо запоминает** обучающие данные, включая шум и случайные особенности, и **теряет способность обобщать** знания на новые данные.

То есть модель показывает **высокую точность на обучающей выборке**, но **плохие результаты на тестовой**.

**Пример:**

Студент заучил ответы на конкретные билеты, но не понял сам предмет.

На экзамене с другими вопросами он “проваливается” - это и есть переобучение.

**Признаки переобучения:**

- Ошибка (loss) на **train** сильно меньше, чем на **test**;

- Модель показывает отличные результаты на знакомых данных, но плохо работает на новых;

- Поведение модели нестабильно: небольшие изменения входных данных дают сильно разные результаты.

**Основные причины переобучения:**

1. **Слишком сложная модель** (много параметров, слоёв, глубины дерева);

2. **Мало данных** - модель «запоминает» шумы;

3. **Долгое обучение** - параметры подгоняются под случайные детали обучающего набора;

4. **Отсутствие регуляризации** - модель ничем не ограничивается;

5. **Неудачное разбиение данных** - тестовые данные похожи на обучающие.

**Как бороться с переобучением:**

- **Регуляризация** (L1, L2, Dropout) - добавляет штраф за слишком большие веса;

- **Упрощение модели** - уменьшение числа параметров или глубины дерева;

- **Больше данных** - особенно если есть шум или дисбаланс;

- **Кросс-валидация** - помогает оценить устойчивость модели;

- **Раннее прекращение обучения (Early stopping)** - остановка, когда ошибка на валидации начинает расти;

- **Аугментация данных** - создание новых примеров на основе существующих (в задачах CV, NLP и т.д.).

## Вопрос №6

> Что такое бейзлайн? Что такое наивный алгоритм? Какие примеры наивных алгоритмов можно привести для задач классификации и регрессии

**Ответ:**

**Бейзлайн (Baseline)** - это **простая отправная точка** при решении задачи машинного обучения.

Он показывает, **насколько хороши ваши данные и метрики**, и служит **ориентиром**: любая новая модель должна работать **лучше бейзлайна**, иначе она бессмысленна.

**Бейзлайн нужен для:**

- Проверки, что задача вообще имеет смысл (данные содержат информацию);

- Сравнения качества моделей;

- Оценки прогресса при улучшении модели.

**Наивный алгоритм (Naive model):**

**Наивный алгоритм** - это **очень простое или "глупое" решение**, часто используемое как бейзлайн.

Он не обучается по-настоящему или использует **минимальные эвристики**, не анализируя закономерности в данных.

То есть - это _самый простой способ решить задачу, не вдаваясь в детали_.

**Примеры наивных алгоритмов:**

| Тип задачи | Пример наивного алгоритма | Идея |
| --------------------------- | ------------------------------------------------------------ | -------------------------------------------------------- |
| **Классификация** | Предсказывать **самый частый класс** (majority class) | «Если 70% — класс 0, всегда предсказывай 0» |
| **Классификация (вариант)** | **Случайный выбор** класса | Предсказывать случайно, пропорционально частотам классов |
| **Регрессия** | Предсказывать **среднее** или **медиану** целевой переменной | «Всегда предсказывай среднее значение Y» |
| **Временные ряды** | Предсказывать **последнее известное значение** | «Завтра будет как сегодня» |
| **Рекомендации** | Рекомендовать **популярные** товары или фильмы | «Показать то, что чаще всего выбирают» |
| **Генерация** | Выдавать **случайный** пример из обучающих данных | «Случайно выбрать похожий объект» |

**Примеры «наивных» моделей:**

- **Naive Bayes Classifier** — классический вероятностный алгоритм, где предполагается, что признаки _независимы_ между собой (наивное, но часто работает хорошо);

- **DummyClassifier / DummyRegressor** из `sklearn` — готовые реализации простых бейзлайнов.

## Вопрос №7

> Как и зачем дискретизировать, бинаризовать, нормализовывать и взвешивать признаки?

**Ответ:**

В машинном обучении **преобразование признаков (feature preprocessing)** помогает упростить данные, сделать их пригодными для обучения и повысить качество модели.

**Дискретизация (Discretization)**

**Что это:**

Преобразование **непрерывных числовых признаков** в **дискретные интервалы** (категории).

**Пример:**

Температура (°C):

`[1, 5, 9, 13, 17, 21, 25, 29]`

→ Разделим на 3 интервала:

`[низкая=0, средняя=1, высокая=2]`

→ `[0, 0, 0, 1, 1, 1, 2, 2]`

**Зачем:**

- Уменьшает влияние шума и выбросов;

- Упрощает структуру данных;

- Подходит для алгоритмов, работающих с категориальными признаками (например, деревья решений);

- Может помочь уменьшить переобучение.

**Бинаризация (Binarization)**

**Что это:**

Преобразование **категориальных признаков** в **набор бинарных (0/1)**.

Самый известный способ - **One-Hot Encoding**.

**Пример:**

Цвет = `[красный, синий, зелёный]`

→ One-hot:

красный = (1,0,0)

синий = (0,1,0)

зелёный = (0,0,1)

**Зачем:**

- Делает категориальные признаки понятными для моделей, работающих с числами (линейная регрессия, SVM, нейросети);

- Избегает ложного "порядка" между категориями (в отличие от label encoding).

Другие варианты кодирования:

- **Label Encoding** - просто заменить категории числами (подходит для деревьев);

- **Binary Encoding** - компактная версия One-Hot для большого числа категорий.

**Нормализация и стандартизация**

**Нормализация (Normalization)** - приведение признаков к **одному масштабу**, например в диапазон `[0, 1]`:

$$

x' = \frac{x - x_{min}}{x_{max} - x_{min}}


$$

**Стандартизация (Standardization)** - приведение к **среднему 0 и стандартному отклонению 1**:

$$

x' = \frac{x - \mu}{\sigma}


$$

**Зачем:**

- Чтобы признаки с разными масштабами **не искажали обучение** (особенно в градиентных методах и KNN);

- Ускоряет и стабилизирует обучение (градиентный спуск сходится быстрее);

- Делает веса интерпретируемыми.

**Пример:**

Если один признак изменяется от 0 до 1, а другой от 0 до 1 000 000 - без нормализации модель будет считать второй важнее просто из-за масштаба.

**Взвешивание признаков (Feature weighting)**

**Что это:**

Назначение признакам **разной важности (веса)** при обучении или при вычислении расстояний между объектами.

**Зачем:**

- Учесть предметную область (некоторые признаки объективно важнее);

- Снизить влияние шумовых признаков;

- Улучшить качество в алгоритмах, где используется расстояние (**kNN**, **K-Means**) или линейная комбинация признаков.

**Примеры:**

- Умножить важный признак на больший коэффициент:

`x_weighted = x * w`

- Использовать **автоматическое взвешивание** через регуляризацию, feature importance (например, в Random Forest или XGBoost).

**Краткое сравнение:**

| Операция | Что делает | Пример | Зачем |
| --------------------------------- | ---------------------------------------------------- | ------------------------------------- | --------------------------------- |
| **Дискретизация** | Делит непрерывные значения на интервалы | Возраст → [0: 0–20, 1: 21–40, 2: 41+] | Упрощение, устойчивость |
| **Бинаризация** | Преобразует категориальные признаки в набор бинарных | Цвет → (is_red, is_blue...) | Для моделей, работающих с числами |
| **Нормализация / стандартизация** | Приводит к единому масштабу | [0, 1000] → [0, 1] | Ускорение и стабильность обучения |
| **Взвешивание** | Назначает признакам разную важность | Вес возраста ↑, вес пола ↓ | Учёт значимости признаков |

## Вопрос №8

> Как и зачем делать one-hot encoding? Можно ли это делать функцией pandas.get_dummies? Чем one-hot отличается от binary-encoding?

**Ответ:**

**Что такое One-Hot Encoding**

**One-Hot Encoding** - это способ преобразования категориальных признаков в числовые,

при котором **каждое уникальное значение категории превращается в отдельный бинарный столбец** (признак).

```md
_Цвет = (красный, синий, красный, зеленый)_

↓ One-hot

is_red | is_blue | is_green
1 | 0 | 0
0 | 1 | 0
1 | 0 | 0
0 | 0 | 1
```

Как раз таки это и можно сделать через `pandas.get_dummies()`

```python
import pandas as pd
df = pd.DataFrame({'color': ['red', 'blue', 'green']})
pd.get_dummies(df, columns=['color'])
```

**Зачем это нужно:**

- Многие модели (линейная регрессия, SVM, нейросети) **не умеют работать с текстовыми или категориальными признаками**;

- **Избегает ложного порядка** между категориями, который создаётся при простом числовом кодировании (`Label Encoding`);

- Делает признаки **взаимно независимыми** - каждая категория кодируется отдельно.

**Недостатки One-Hot Encoding**

- При большом количестве категорий (например, тысячах значений) создаётся **очень много столбцов** → растёт размерность и время обучения;

- Может вызвать **разреженность данных** (sparse matrix), особенно при малом количестве наблюдений.

**Binary Encoding - альтернатива One-Hot**

**Binary Encoding** решает проблему большого количества столбцов:

- Каждой категории присваивается уникальный номер;

- Этот номер переводится в **двоичное представление**;

- Каждый бит становится отдельным бинарным признаком.

```md
Категории: [A, B, C, D]
→ Номера: [1, 2, 3, 4]
→ Бинарно: [01, 10, 11, 100]
→ Признаки:

bit1 | bit2 | bit3
0 | 0 | 1
0 | 1 | 0
0 | 1 | 1
1 | 0 | 0
```

**Сравнение One-Hot и Binary Encoding**

| Характеристика | **One-Hot Encoding** | **Binary Encoding** |
| -------------------- | --------------------------------- | ----------------------------------- |
| Количество признаков | = числу категорий | ≈ log₂(число категорий) |
| Интерпретируемость | Простая и понятная | Менее очевидна |
| Производительность | Медленнее при множестве категорий | Быстрее при большом числе категорий |
| Когда использовать | До ~100 категорий | Когда категорий очень много (1000+) |

## Вопрос №9

> Как вычисляется cross-entropy и почему она cross?

**Ответ:**

**Cross-Entropy Loss** - это функция потерь, которая измеряет, насколько сильно распределение предсказанных вероятностей модели отличается от истинного распределения меток.

**Формула (бинарная классификация)**

$$

L = - \frac{1}{n} \sum_{i=1}^{n} [y_i \log(p_i) + (1 - y_i) \log(1 - p_i)]


$$

где:

- $y_i \in \{0, 1\}$ - истинная метка,

- $p_i = \sigma(x_i)$ - предсказанная вероятность класса 1,

- $\sigma(x)$ - сигмоида, преобразующая логиты в вероятности.

Если модель уверена и права — потеря близка к 0.

Если модель уверена, но ошибается — потеря сильно растёт.

**Для многоклассовой классификации**

$$

L = - \sum_{c=1}^{M} y_{o,c} \log(p_{o,c})


$$

где:

- $y_{o,c}$ - индикатор (1, если объект \(o\) принадлежит классу \(c\));

- $p_{o,c}$ - вероятность, что модель отнесёт объект \(o\) к классу \(c\);

- $M$ - количество классов.

**Почему она называется _cross_-entropy?**

“Cross” - потому что это **перекрёстная энтропия между двумя распределениями**:

$$

H(p, q) = -\sum p(x) \log q(x)


$$

- $p(x)$ - _истинное распределение_ (ground truth, “one-hot” метки);

- $q(x)$ - _предсказанное распределение_ модели.

То есть мы **измеряем энтропию истинного распределения, используя вероятности модели** - “перекрёстно”.

Если бы \(p=q\), то это была бы просто **энтропия**:

$$

H(p) = -\sum p(x) \log p(x)


$$

**Интуитивно:**

- Если истинная метка **y=1**, то потеря $-\log(p)$ быстро растёт, когда \(p\) близко к 0

- Если **y=0**, то берём вторую часть формулы $-\log(1 - p)$

![[Pasted image 20251013230106.png]]

Когда совместить две кривые (для y=0 и y=1), они образуют **“крест” (cross)** - отсюда и визуальное объяснение термина:

модель “перекрещивает” два сценария: ошибку для класса 0 и для класса 1.

**Почему это хорошая функция потерь:**

- Наказывает уверенные, но неверные предсказания сильнее, чем неуверенные;

- Стимулирует модель выдавать **реалистичные вероятности**;

- Является гладкой и дифференцируемой - подходит для градиентного спуска;

- Прямо связана с максимизацией правдоподобия (Maximum Likelihood Estimation).

## Вопрос №10

> Зачем делить данные на train, test, val? Чем val отличается от test? Кросс-валидация, ее виды. Что такое data leak

**Ответ:**

**Train (обучающая выборка)**

Используется для **обучения модели** - подбора параметров (весов).

Модель “учится” находить закономерности именно на этих данных.

**Validation (валидационная выборка)**

Используется для **подбора гиперпараметров** и **оценки качества** во время обучения.

- помогает следить за переобучением (если на train всё лучше, а на val хуже - модель переобучается);

- используется при **early stopping**;

- _важно:_ модель “видит” эти данные косвенно, через оптимизацию гиперпараметров.

**Test (тестовая выборка)**

Используется **только один раз - для финальной оценки модели.**

Модель не должна “видеть” эти данные **ни напрямую, ни косвенно.**

→ Это имитация работы модели на реальных, ранее невиданных данных.

**Почему нужно делить данные:**

- чтобы корректно измерить способность модели _обобщать_, а не просто запоминать;

- чтобы избежать “подглядывания” в тест, которое приводит к ложному ощущению высокого качества (data leakage).

**Разница между Validation и Test**

| Параметр | Validation | Test |
| ------------------------------ | ----------------------- | ------------------ |
| Используется для | Подбора гиперпараметров | Финальной оценки |
| Влияет на обучение | Да (через выбор модели) | Нет |
| Видит ли модель данные | Частично | Никогда |
| Можно использовать многократно | Да | Нет - только 1 раз |

**Кросс-валидация (Cross-validation)**

**Идея:**

Если данных немного, можно использовать их эффективнее, многократно чередуя обучение и проверку.

**K-Fold Cross-Validation**

1. Разделяем данные на _k_ частей (folds);

2. _k_ раз обучаем модель:

- на _k−1_ частях - train;

- на оставшейся - validation;

3. Итоговая метрика - среднее значение по всем итерациям.

Позволяет получить **устойчивую оценку качества**, не теряя данных на отдельную validation-выборку.

**Виды:**

- **K-Fold** - базовый вариант;

- **Stratified K-Fold** - сохраняет соотношение классов (важно при дисбалансе);

- **Leave-One-Out (LOO)** - особый случай, когда каждый пример по очереди становится тестом;

- **TimeSeries Split** - для временных рядов (учитывает порядок времени, не перемешивает данные).

**Data Leakage (утечка данных)**

**Data Leak** - это ситуация, когда информация из теста (или целевой переменной) **неявно попадает в процесс обучения**.

В результате модель “читает ответы” и показывает нереально высокие метрики, но **проваливается на реальных данных**.

**Примеры:**

- Вычисление статистик (mean, std) по всему датасету, включая test;

- Использование фич, напрямую зависящих от таргета (например, “revenue_next_month” при прогнозе текущего месяца);

- Подбор гиперпараметров по тестовой выборке.

**Правильный подход:**

Все трансформации (нормализация, масштабирование, кодирование) нужно **fit’ить только на train**, а затем **применять (transform)** к validation и test.

## Вопрос №11

> Что такое регуляризация? Как устроены L1 и L2 регуляризации

**Ответ:**

**Регуляризация** — это способ **борьбы с переобучением**, при котором к функции потерь добавляется **штраф за сложность модели** (обычно за большие веса).

**Идея:**

> Модель должна быть не только точной на обучении, но и достаточно “простой” (гладкой), чтобы не запоминать шум.

**Общая форма функции потерь с регуляризацией**

$$

\min_w \; L(X, y, w) = \min_w \left( \|Xw - y\|^2 + \lambda \|w\|_k \right)


$$

где

- $|Xw - y\|^2$ — основная ошибка (например, MSE),

- $\lambda$ — коэффициент регуляризации (гиперпараметр),

- $|w\|_k$ — штраф за сложность модели (в зависимости от типа регуляризации).

**L1-регуляризация (Lasso)**

$$

\|w\|_1 = |w_1| + |w_2| + ... + |w_D|


$$

Добавляется штраф пропорционально **абсолютным значениям весов**.

- Зануляет часть весов → делает модель **разреженной (sparse)**.

- Может использоваться для **отбора признаков**.

- Но менее устойчива при мультиколлинеарности (если признаки сильно коррелированы).

Пример:

$$

L = MSE + \lambda \sum |w_i|


$$

**L2-регуляризация (Ridge)**

$$

\|w\|_2^2 = w_1^2 + w_2^2 + ... + w_D^2


$$

Добавляется штраф пропорционально **квадратам весов**.

- “Сжимает” все веса, но **не зануляет** их.

- Делает модель **более стабильной** и устойчивой к шуму и мультиколлинеарности.

- Часто используется по умолчанию (например, в `LinearRegression` → `Ridge`).

$$

L = MSE + \lambda \sum w_i^2


$$

**Elastic Net (L1 + L2)**

**Комбинирует оба подхода:**

$$

L = MSE + \lambda_1 \sum |w_i| + \lambda_2 \sum w_i^2


$$

- Контролирует и разреженность, и стабильность;

- Применяется, когда много признаков, часть из которых коррелированы.

**Геометрическая интуиция**

- **L1** ограничивает веса “ромбом” → некоторые пересечения с осями → зануление весов.

- **L2** ограничивает веса “кругом” → веса уменьшаются плавно, но не становятся нулевыми.

**Сравнение L1 и L2**

| Характеристика | **L1 (Lasso)** | **L2 (Ridge)** |
| ----------------------------- | -------------------- | -------------- |
| Формула штрафа | ∑\|w_i\| | ∑w_i² |
| Эффект на веса | Обнуляет часть весов | Уменьшает все |
| Результат | Разреженная модель | Гладкая модель |
| Отбор признаков | Да | Нет |
| Чувствительность к корреляции | Высокая | Низкая |
| Решение | Неаналитическое | Аналитическое |

## Вопрос №12

> Метрики классификации: precision, recall, accuracy, F1, F-beta, roc auc кривая и как она строится, confusion matrix

**Ответ:**

Метрики классификации оценивают качество предсказаний модели.

Особенно важно различать случаи, когда данные **несбалансированы** (например, 95% одного класса и 5% другого).

![[Pasted image 20251013235606.png]]

**Accuracy**

Доля правильных предсказаний:

$$

Accuracy = \frac{TP + TN}{TP + TN + FP + FN}


$$

- Простая, понятная метрика.

- Плохо работает при **дисбалансе классов** (можно “наугад” предсказывать самый частый класс и получить высокую точность).

**Precision (точность)**

$$

Precision = \frac{TP}{TP + FP}


$$

Из всех объектов, предсказанных как “положительные”, - **сколько действительно положительные**?

> «Насколько модель уверена в своих положительных предсказаниях».

**Пример:** при фильтрации спама — сколько писем, которые модель пометила как спам, **действительно спам?**

**Recall (полнота)**

$$

Recall = \frac{TP}{TP + FN}


$$

Из всех реальных положительных объектов — **сколько модель нашла?**

> «Насколько хорошо модель находит все случаи положительного класса».

**Пример:** при диагностике болезней — сколько больных людей модель действительно определила как больных?

**F1-score**

$$

F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}


$$

Это **гармоническое среднее** между Precision и Recall.

Используется, когда важно найти **баланс** между пропусками и ложными срабатываниями.

> F1 высокий только тогда, когда и Precision, и Recall высоки.

**Fβ-score**

$$

F_\beta = (1 + \beta^2) \cdot \frac{Precision \cdot Recall}{(\beta^2 \cdot Precision) + Recall}


$$

Позволяет **задать приоритет**:

- $\beta > 1$ — важнее **Recall** (лучше поймать всех, даже ценой FP);

- $\beta < 1$ — важнее **Precision** (лучше меньше FP, но увереннее).

**ROC-кривая (Receiver Operating Characteristic)**

![[Pasted image 20251014000055.png]]

ROC-кривая показывает, **как меняются качество классификации при разных порогах** вероятности.

**По осям:**

- X: **FPR** = FP / (FP + TN) — доля ложных срабатываний;

- Y: **TPR (Recall)** = TP / (TP + FN) — доля правильно найденных положительных.

**Процесс:**

1. Модель выдаёт вероятности (например, 0.1, 0.7, 0.9…);

2. Меняем порог классификации от 0 до 1;

3. Для каждого порога считаем (FPR, TPR);

4. Строим кривую ROC.

**AUC (Area Under Curve)**

![[Pasted image 20251014000201.png]]

**AUC ROC** = площадь под ROC-кривой (от 0 до 1).

| AUC значение | Интерпретация |
| ------------ | ------------------------------ |
| 0.5 | модель как случайный выбор |
| > 0.7 | неплохая модель |
| > 0.9 | отличная модель |
| 1.0 | идеальная (скорее переобучена) |

**Интуитивно:**

AUC = вероятность, что модель поставит более высокую вероятность положительному объекту, чем отрицательному.

**Многоклассовая классификация**

Если классов больше двух:

- **macro average** — считаем метрику для каждого класса, затем усредняем (все классы равны);

- **micro average** — считаем общие TP, FP, FN по всем классам (учитывает дисбаланс).

**Краткое сравнение:**

| Метрика | Показывает | Учитывает дисбаланс | Когда полезна |
| -------------------- | ----------------------- | ------------------- | ------------------------------------ |
| **Accuracy** | Общая доля верных | - | Когда классы сбалансированы |
| **Precision** | Чистоту предсказаний | + | Когда важна уверенность (спам, фрод) |
| **Recall** | Полноту обнаружений | + | Когда важно не пропустить (медицина) |
| **F1** | Баланс precision/recall | + | При дисбалансе классов |
| **ROC-AUC** | Качество ранжирования | + | При любых дисбалансах |
| **Confusion matrix** | Подробный разбор ошибок | + | Для анализа поведения модели |

## Вопрос №13

> Метрики регрессии: mae, mse, (s-)mape

**Ответ:**

Метрики регрессии измеряют, **насколько хорошо модель предсказывает числовые значения**.

Чем **меньше значение метрики**, тем **лучше модель**.

**Mean Absolute Error (MAE)**

$$

MAE = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y_i}|


$$

**Смысл:** средняя величина ошибки в тех же единицах, что и целевая переменная.

**Интерпретация:** “в среднем модель ошибается на X единиц”.

- Проста в понимании.

- Не учитывает, насколько сильно выбиваются отдельные ошибки.

Если реальные цены — (100, 200, 300), а предсказанные — (90, 220, 280),

MAE = (10 + 20 + 20) / 3 = **16.7**.

**Mean Squared Error (MSE)**

$$

MSE = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y_i})^2


$$

**Смысл:** усреднённый квадрат ошибки.

Большие ошибки **штрафуются сильнее**, чем маленькие.

- Подходит, если важно избегать крупных промахов.

- Измеряется в квадрате исходных единиц (труднее интерпретировать).

**Root Mean Squared Error (RMSE)**

$$

RMSE = \sqrt{MSE}


$$

**Смысл:** возвращает ошибку в тех же единицах, что и целевая переменная.

**Интерпретация:** средняя величина отклонения между прогнозом и фактом.

**Mean Absolute Percentage Error (MAPE)**

$$

MAPE = \frac{100\%}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y_i}}{y_i}\right|


$$

**Смысл:** показывает ошибку **в процентах** от фактического значения.

- Удобно для бизнес-интерпретации (“ошибка прогноза — 8%”).

- Не работает, если \(y_i = 0\); переоценивает ошибки при малых y.

Пример: если прогноз 110 при реальном 100,

ошибка = |100−110|/100 = 10% → MAPE = 10.

**Symmetric MAPE (SMAPE)**

$$

SMAPE = \frac{100\%}{n} \sum_{i=1}^{n} \frac{2|y_i - \hat{y_i}|}{|y_i| + |\hat{y_i}|}


$$

**Смысл:** симметричный вариант MAPE — учитывает как переоценку, так и недооценку.

- Не “взрывается” при \(y_i = 0\).

- Нормирована в диапазоне (0, 200%).

- Менее интуитивна для интерпретации.

**Дополнительно: R² (коэффициент детерминации)**

$$

R^2 = 1 - \frac{\sum (y_i - \hat{y_i})^2}{\sum (y_i - \bar{y})^2}


$$

Показывает, **какая доля дисперсии данных объясняется моделью**.

- \(R^2 = 1\) — идеальная модель;

- \(R^2 = 0\) — не лучше, чем просто среднее;

- \(R^2 < 0\) — модель хуже среднего.

## Вопрос №14

> Вопрос-приз: можно ли использовать модели машинного обучения для заполнения пропущенных данных в датасете?

**Ответ:**

Да, можно — и это часто делают

**Идея:**

Пропущенные значения можно рассматривать как **отдельную задачу предсказания**:

- если признак числовой → задача **регрессии**,

- если признак категориальный → задача **классификации**.

То есть модель учится по “непропущенным” значениям и **предсказывает недостающие** на основе других признаков

**Примеры подходов:**

| Метод | Тип данных | Идея |
| ------------------------------------------------- | ------------------------- | ------------------------------------------------------------------------------- |
| **KNN Imputer (k ближайших соседей)** | числовые / категориальные | Находит k похожих объектов и берёт среднее (для чисел) или моду (для категорий) |
| **Линейная / логистическая регрессия** | числовые / бинарные | Строим модель, которая предсказывает пропуски по остальным фичам |
| **Random Forest / XGBoost** | любые | Более точный, учитывает нелинейности |
| **Множественная импутация (Multiple Imputation)** | любые | Строит несколько моделей для разных подмножеств и усредняет предсказания |
| **Autoencoder / нейросеть** | числовые | Учится восстанавливать неполные данные по структуре набора |

**Когда стоит (и не стоит) использовать ML для заполнения:**

**Когда стоит:**

- Пропусков немного, но они важны;

- Есть сильная корреляция между признаками;

- Хотим минимизировать искажения данных.

**Когда не стоит:**

- Пропусков очень много → модель просто “догадывается” наугад;

- Признаки независимы друг от друга → ML не поможет;

- Мы используем эти же признаки позже для обучения модели → возможен **data leakage** (утечка данных).

**Альтернативы (без ML)**

- Замена средним / медианой / модой;

- Интерполяция (по времени или соседям);

- Введение отдельной категории “Unknown” для категориальных признаков.

## Вопрос №15

> Дисбаланс классов: как влияет на метрики и модели, как с этим справиться

**Ответ:**

**Дисбаланс классов** — это ситуация, когда одни классы в данных встречаются **значительно чаще**, чем другие.

**Примеры:**

- 99% транзакций — нормальные, 1% — мошенничество.

- 95% пациентов здоровы, 5% больны.

**Почему это проблема:**

1. **Модель смещается** в сторону большинства (предсказывает его почти всегда).

→ Можно получить accuracy = 99%, просто говоря “все норм”.

2. **Обычные метрики вводят в заблуждение**:

- **Accuracy** будет высокой, даже если модель не видит редкий класс.

- **Precision / Recall / F1** — дают более честную оценку.

3. **Переобучение на частом классе** — модель “запоминает” паттерны только мажоритарного класса.

**Как влияет на метрики:**

| Метрика | Что происходит при дисбалансе |
| --------------------------------- | -------------------------------------------------------- |
| **Accuracy** | Становится бесполезной (высока даже при плохом качестве) |
| **Precision / Recall** | Более информативны, но нужно смотреть оба |
| **F1-score** | Балансирует precision и recall |
| **ROC-AUC** | Сохраняет устойчивость к дисбалансу |
| **PR-AUC (Precision-Recall AUC)** | Часто информативнее, чем ROC-AUC при сильном дисбалансе |

**Как бороться с дисбалансом:**

**Корректировать данные**

- **Oversampling (пересэмплирование меньшинства)** — дублируем объекты редкого класса или создаём синтетические примеры

(например, метод **SMOTE** — Synthetic Minority Oversampling Technique).

- **Undersampling (удаление части большинства)** — уменьшаем количество примеров частого класса.

_Минус:_ теряем часть данных.

- **Аугментация данных** — создаём новые примеры с помощью шумов, преобразований, генераторов (в задачах CV, NLP и др.).

**Изменить обучение модели**

- **Взвешивание классов (class weights)** — штраф за ошибку в редком классе делаем выше.

Пример: `class_weight='balanced'` в sklearn.

- **Cost-sensitive learning** — явно задаём разные стоимости ошибок (FP/FN).

- **Использовать подходящие алгоритмы** — деревья, бустинги, ансамбли (Random Forest, XGBoost) могут устойчиво работать при дисбалансе.

**Менять постановку задачи**

- Рассматривать редкий класс как **аномалию (anomaly detection)**;

- Переформулировать задачу (например, бинаризация “редкий vs остальные”).

**Как оценивать модель при дисбалансе**

Использовать метрики, чувствительные к редкому классу:

- **Precision, Recall, F1-score (macro / weighted)**

- **ROC-AUC, PR-AUC**

- **Confusion Matrix** — чтобы видеть, где именно ошибки.

Пример

При 99% "0" и 1% "1":

модель, всегда предсказывающая “0”

→ Accuracy = 0.99

→ Recall для класса “1” = 0

→ F1 = 0

## Вопрос №16

> Градиентный спуск. Как оптимизирует параметры моделей, что такое пространство ошибок, чем отличаются (мини-)батчевый и стохастический

**Ответ:**

**Идея:** минимизируем функцию потерь $L(w)$ пошагово.

Обновление весов:

$$
w \leftarrow w - \eta ,\nabla_w L(w)
$$

где $\eta$ — скорость обучения, $\nabla_w L$ — градиент.

**Пространство ошибок:** гиперповерхность значений $L(w)$ над пространством параметров. Каждая точка — набор весов, высота — значение потерь.

**Варианты:**

- **Batch GD:** градиент по всей выборке. Стабильно, медленно.

- **Stochastic GD (SGD):** по одному объекту. Быстро, шумно, помогает выходить из локальных минимумов.

- **Mini-batch GD:** по мини-пакету $m$ объектов. Компромисс скорость/стабильность. Стандарт де-факто.

**Практика:** нормализация признаков, убывающий $\eta$, моменты/адаптивные методы (Momentum, Adam), early stopping.

## Вопрос №17 X

> Модель линейная регрессия

**Ответ:**

**Модель:** $\hat y = Xw + b$.

**Обучение (MSE):**

$$
\min*{w,b}; \frac{1}{n}\sum*{i=1}^{n}(y_i - \hat y_i)^2
$$

Решение: нормальные уравнения $w=(X^\top X)^{-1}X^\top y$ при полноранговости, либо градиентные методы.

**Регуляризация:**

- Ridge: $+\lambda|w|\_2^2$ — сглаживает веса.

- Lasso: $+\lambda|w|\_1$ — зануляет часть весов.

- Elastic Net: комбинирует L1 и L2.

**Предпосылки классической МНК:** линейность, независимые ошибки, гомоскедастичность, нормальность ошибок (для интервалов).

## Вопрос №18 X

> Модель логистическая регрессия

**Ответ:**

**Модель вероятности класса 1:**

$$
p(y=1\mid x)=\sigma(w^\top x+b)=\frac{1}{1+e^{-(w^\top x+b)}}
$$

**Потери (бинарная кросс-энтропия):**

$$
\min*{w,b}; -\frac{1}{n}\sum*{i=1}^{n}\big[y_i\log p_i+(1-y_i)\log(1-p_i)\big]
$$

Оптимизация градиентными методами с L2/L1 регуляризацией.

**Декодирование:** порог по $p$ (обычно 0.5). Порог сдвигают под бизнес-стоимости ошибок.

**Мультикласс:** one-vs-rest или softmax-регрессия.

## Вопрос №19

### Модель "Дерево решений" (Decision Tree)

Идея:  
Модель последовательно делит данные по признакам так, чтобы увеличить “чистоту” в каждом подмножестве.  
Каждый внутренний узел — это вопрос (условие),  
каждая ветка — возможный ответ,  
а листья — конечные прогнозы (класс или число).

---

### Как работает дерево решений

1. В корне выбирается признак, который лучше всего разделяет выборку.  
2. Данные делятся на подмножества по этому признаку (ветвление).  
3. Процесс повторяется рекурсивно, пока не достигнуто:
   - максимальная глубина,
   - минимальное количество объектов в листе,
   - или чистота подмножества (все объекты одного класса).

---

### Критерии разбиения

Цель — максимизировать "информационный выигрыш" (Information Gain).  
Это измеряет, насколько хорошо признак разделяет данные.

| Тип задачи | Критерий | Формула / интуиция |
|-------------|-----------|--------------------|
| Классификация | Gini impurity | $G = 1 - \sum p_i^2$ (чем меньше, тем “чище”) |
| Классификация | Entropy | $H = - \sum p_i \log_2(p_i)$ |
| Регрессия | MSE / MAE reduction | деление выбирается по минимальной ошибке в поддеревьях |

---

### Преимущества дерева

Интерпретируемая модель ("если ... то ...")  
Работает без нормализации признаков  
Может работать с категориальными фичами и нелинейностями  

Склонна к переобучению, особенно при большой глубине  
Нестабильна — небольшое изменение данных может сильно изменить дерево

---

### Модель "Случайный лес" (Random Forest)

Random Forest = ансамбль из многих деревьев решений, обученных на разных подвыборках данных и признаков.

Идея:  
> “Пусть каждое дерево ошибается по-своему, а при голосовании ошибки взаимно компенсируются.”

---

### Как работает случайный лес

1. Из исходных данных создаются случайные подвыборки (с возвращением) — bagging.  
2. Для каждого дерева случайно выбирается подмножество признаков.  
3. Каждое дерево строится независимо.  
4. Итоговое предсказание:
   - для классификации — голосование большинства;
   - для регрессии — усреднение предсказаний.

---

### Преимущества случайного леса

Устойчив к переобучению  
Хорошо работает “из коробки”  
Даёт оценку важности признаков  
Труднее интерпретировать, чем одно дерево  
Медленнее при большом количестве деревьев

---

### Как считается важность признаков (feature importance)

Feature importance показывает, насколько данный признак снижает ошибку / неопределённость при разбиениях дерева.

#### 1. По уменьшению критерия (Gini / Entropy)
Наиболее распространённый способ (в sklearn по умолчанию):

1. Для каждого узла дерева считается, насколько улучшилось качество после разбиения (например, уменьшилась Gini impurity).  
2. Это улучшение (gain) приписывается признаку, по которому было разбиение.  
3. Вклад всех узлов по признаку суммируется и нормируется.

$$
Importance(feature_j) = \frac{\sum_{nodes \ where \ split=j} (impurity_{parent} - impurity_{left} - impurity_{right}) \times samples_{node}}{\text{total gain}}
$$

Быстро и наглядно  
Может переоценивать признаки с большим количеством уникальных значений (например, числовые фичи)

---

#### 2. По уменьшению точности при перестановке (Permutation Importance)
- После обучения перемешивают значения признака j (разрушают связь с таргетом);
- Считают, насколько ухудшилось качество модели;
- Чем сильнее ухудшение — тем важнее признак.

Более честная оценка  
Дольше вычисляется

---

### Интуитивно
Если удалить или “испортить” важный признак — дерево начнёт ошибаться гораздо чаще.  
Если ошибка почти не изменилась — признак незначим.

---

Итог:
> Дерево решений — интерпретируемая, но нестабильная модель.  
> Случайный лес — ансамбль деревьев, который снижает переобучение.  
> Feature importance показывает, какие признаки чаще и сильнее влияют на разбиения.

## Вопрос №20

### Ансамблирование алгоритмов (Ensemble Learning)

Ансамблирование — это подход, при котором объединяются несколько моделей, чтобы получить более точный и устойчивый результат, чем каждая модель по отдельности.

Идея:  
> “Группа слабых моделей может работать лучше одной сильной”.

---

### Основные типы ансамблей

| Тип | Принцип | Пример |
|------|----------|---------|
| Бэггинг (Bagging) | Обучаем модели независимо на разных подвыборках данных и усредняем их предсказания | Random Forest |
| Бустинг (Boosting) | Обучаем модели последовательно, каждая исправляет ошибки предыдущей | AdaBoost, Gradient Boosting, XGBoost |
| Стекинг (Stacking) | Обучаем несколько разных моделей и потом метамодель, которая учится комбинировать их предсказания | StackEnsemble, Blending |

---

### Бэггинг (коротко)

- Модели обучаются параллельно на случайных подвыборках данных (с возвращением).
- Предсказания усредняются (для регрессии) или голосуются (для классификации).
- Снижает дисперсию и риск переобучения.  

Пример: Random Forest — ансамбль деревьев решений, где каждое дерево обучается на случайном подмножестве признаков и объектов.

---

### Бустинг (Boosting)

Бустинг — последовательное ансамблирование слабых моделей (обычно деревьев решений).  
Каждая следующая модель учится исправлять ошибки предыдущей.

Идея:  
> Учимся “на ошибках” — новые модели фокусируются на объектах, где предыдущие ошибались.

---

### Математическая интуиция бустинга

1. Изначально модель делает простое предсказание (например, среднее по данным).  
2. Вычисляем ошибку (остатки, residuals).  
3. Обучаем следующую модель предсказывать эти ошибки.  
4. Итоговое предсказание = сумма (или взвешенная сумма) всех базовых моделей.

$$
\hat{y} = \sum_{m=1}^M \alpha_m h_m(x)
$$

где  
- $h_m(x)$ — слабая модель (например, дерево),  
- $\alpha_m$ — вес модели,  
- $M$ — количество итераций (глубина бустинга).

---

### Примеры бустингов

| Алгоритм | Ключевая идея |
|-----------|----------------|
| AdaBoost | Каждая следующая модель получает больший вес для объектов, где были ошибки. Ошибочные примеры становятся “важнее”. |
| Gradient Boosting (GBM) | Модели учатся предсказывать градиенты функции потерь. Более гибкий и устойчивый способ. |
| XGBoost, LightGBM, CatBoost | Современные оптимизированные реализации GBM. Ускоряют обучение и уменьшают переобучение. |

---

### Преимущества и недостатки бустинга

Плюсы:
- Очень высокая точность;
- Умеет работать с нелинейными зависимостями;
- Хорошо обрабатывает несбалансированные данные.

Минусы:
- Медленнее в обучении (последовательный процесс);
- Склонен к переобучению без регуляризации;
- Много гиперпараметров (learning rate, depth, n_estimators и т.д.).

---

### Пример интуиции

Представь, что у тебя 10 студентов, каждый немного ошибается на тесте.  
Если собрать их ответы вместе (усреднить или проголосовать),  
результат будет точнее, чем у любого отдельного студента.

---

Итог:
> Ансамблирование — это “коллективный разум” моделей.  
> Бэггинг уменьшает разброс (variance),  
> бустинг уменьшает смещение (bias),  
> а вместе они делают модель сильнее и устойчивее.
